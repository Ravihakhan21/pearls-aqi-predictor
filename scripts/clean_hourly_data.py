import pandas as pd
from datetime import datetime

# ğŸ“‚ File paths
raw_file = "data/aqi_data.json"          # âœ… CI/CD keeps updating this
clean_file = "data/hourly_clean.csv"     # âœ… We'll generate this cleaned version

print("ğŸ“¥ Loading raw AQI data...")
df = pd.read_json(raw_file)

print(f"âœ… Raw file loaded: {len(df)} rows")

# ----------------- ğŸ§¹ CLEANING -----------------

# 1ï¸âƒ£ Fix timestamp format â†’ YYYY-MM-DD HH:MM
print("ğŸ•’ Standardizing timestamps...")
df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

# 2ï¸âƒ£ Drop rows where timestamp could not be parsed (corrupted rows)
before = len(df)
df = df.dropna(subset=['timestamp'])
print(f"ğŸ—‘ï¸ Dropped {before - len(df)} bad timestamp rows")

# 3ï¸âƒ£ Drop rows where all pollutant & weather values are missing
pollutants_weather = ['o3', 'co', 'no2', 'so2', 'temp_c', 'humidity', 'wind_kph', 'pressure_mb']
before = len(df)
df = df.dropna(subset=pollutants_weather, how='all')
print(f"ğŸ—‘ï¸ Dropped {before - len(df)} empty pollutant rows")

# 4ï¸âƒ£ Remove duplicates by timestamp (keep latest)
before = len(df)
df = df.drop_duplicates(subset=['timestamp'], keep='last')
print(f"ğŸ—‘ï¸ Dropped {before - len(df)} duplicate timestamps")

# 5ï¸âƒ£ Sort chronologically
df = df.sort_values('timestamp')

# ----------------- ğŸ’¾ SAVE -----------------
df.to_csv(clean_file, index=False)
print(f"ğŸ‰ Clean hourly dataset saved to {clean_file}")
print(f"ğŸ“Š Final rows: {len(df)} (âœ… ready for ML, charts & retraining)")
